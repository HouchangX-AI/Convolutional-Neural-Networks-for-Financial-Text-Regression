{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import spacy\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "import torch.nn.functional as F\n",
    "import string\n",
    "from torch.utils.data import Dataset\n",
    "from collections import Counter\n",
    "import os\n",
    "from scipy.stats import spearmanr\n",
    "from nltk.stem import PorterStemmer\n",
    "import pickle as pkl\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "torch.cuda.set_device(3)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "MAX_SENTENCE_LENGTH = 20000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using:  3\n"
     ]
    }
   ],
   "source": [
    "print('Using: ', torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read stock as dictionary\n",
    "def read_stock(year='2013'):\n",
    "    path = 'data/all.logvol/' + year + '.logvol.+12.txt'\n",
    "    stock_dic = {}\n",
    "    for line in open(path):\n",
    "        v, k = line.rstrip().split()\n",
    "        v = float(v)\n",
    "        stock_dic[k] = v\n",
    "    return stock_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read report and combine with stock\n",
    "def read_report(year='2013'):\n",
    "    path = 'data/all.tok/'+year+'.tok/'\n",
    "    stock_dic = read_stock(year)\n",
    "    files =os.listdir(path)\n",
    "    all_txt = []\n",
    "    all_targets = []\n",
    "    for file in files:\n",
    "        report_name = file.split('.')[0]\n",
    "        text = [line.rstrip() for line in open(path+file)]\n",
    "        all_txt.extend(text)\n",
    "        all_targets.append(stock_dic[report_name])\n",
    "    return all_txt, all_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "train_targets = []\n",
    "for year in ['2008', '2009','2010']:\n",
    "    all_txt, all_targets = read_report(year=year)\n",
    "    train_data.extend(all_txt)\n",
    "    train_targets.extend(all_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data, val_targets = read_report(year='2011')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tokenize and build vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = spacy.load('en_core_web_sm')\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "#create n-gram datasets\n",
    "def tokenize_dataset(dataset, n_gram=1):\n",
    "    token_dataset = []\n",
    "        # we are keeping track of all tokens in dataset \n",
    "        # in order to create vocabulary later\n",
    "    all_tokens = []\n",
    "    for sample in dataset:\n",
    "        tokens = sample.split()\n",
    "        n_tokens = []\n",
    "        for i in range(len(tokens)-n_gram+1): \n",
    "            n_token = ' '.join(tokens[i:i+n_gram])\n",
    "            n_tokens.append(stemmer.stem(n_token))\n",
    "        token_dataset.append(n_tokens)\n",
    "        all_tokens += n_tokens\n",
    "    return token_dataset, all_tokens\n",
    "\n",
    "def build_vocab(all_tokens, max_vocab_size = None):\n",
    "    # Returns:\n",
    "    # id2token: list of tokens, where id2token[i] returns token that corresponds to token i\n",
    "    # token2id: dictionary where keys represent tokens and corresponding values represent indices\n",
    "    # save index 0 for unk and 1 for pad\n",
    "    PAD_IDX = 0\n",
    "    UNK_IDX = 1\n",
    "    token_counter = Counter(all_tokens)\n",
    "    if not max_vocab_size:\n",
    "        max_vocab_size = len(all_tokens)\n",
    "    vocab, count = zip(*token_counter.most_common(max_vocab_size))\n",
    "    id2token = list(vocab)\n",
    "    token2id = dict(zip(vocab, range(2,2+len(vocab)))) \n",
    "    id2token = ['<pad>', '<unk>'] + id2token\n",
    "    token2id['<pad>'] = PAD_IDX \n",
    "    token2id['<unk>'] = UNK_IDX\n",
    "    return token2id, id2token\n",
    "\n",
    "# convert token to id in the dataset\n",
    "def token2index_dataset(tokens_data):\n",
    "    indices_data = []\n",
    "    for tokens in tokens_data:\n",
    "        index_list = [token2id[token] if token in token2id else UNK_IDX for token in tokens]\n",
    "        indices_data.append(index_list)\n",
    "    return indices_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    \"\"\"\n",
    "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
    "    Note that this class inherits torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_list, target_list):\n",
    "        \"\"\"\n",
    "        @param data_list: list of newsgroup tokens \n",
    "        @param target_list: list of newsgroup targets \n",
    "\n",
    "        \"\"\"\n",
    "        self.data_list = data_list\n",
    "        self.target_list = target_list\n",
    "        assert (len(self.data_list) == len(self.target_list))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        \n",
    "        token_idx = self.data_list[key][:MAX_SENTENCE_LENGTH]\n",
    "        label = self.target_list[key]\n",
    "        return [token_idx, len(token_idx), label]\n",
    "\n",
    "def collate_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all \n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    label_list = []\n",
    "    length_list = []\n",
    "\n",
    "    for datum in batch:\n",
    "        label_list.append(datum[2])\n",
    "        length_list.append(datum[1])\n",
    "    # padding\n",
    "    for datum in batch:\n",
    "        padded_vec = np.pad(np.array(datum[0]), \n",
    "                                pad_width=((0,MAX_SENTENCE_LENGTH-datum[1])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        data_list.append(padded_vec)\n",
    "    return [torch.from_numpy(np.array(data_list)).to(device), torch.LongTensor(length_list).to(device), torch.DoubleTensor(label_list).to(device)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train set tokens\n",
    "# print (\"Tokenizing train data\")\n",
    "# train_data_tokens, all_train_tokens = tokenize_dataset(train_data)\n",
    "# pkl.dump(train_data_tokens, open(\"data/train_data_tokens.p\", \"wb\"))\n",
    "# pkl.dump(all_train_tokens, open(\"data/all_train_tokens.p\", \"wb\"))\n",
    "# # val set tokens\n",
    "# print (\"Tokenizing val data\")\n",
    "# val_data_tokens, _ = tokenize_dataset(val_data)\n",
    "# pkl.dump(val_data_tokens, open(\"data/val_data_tokens.p\", \"wb\"))\n",
    "\n",
    "# run code above if these files do not exist\n",
    "train_data_tokens = pkl.load(open(\"data/train_data_tokens.p\", \"rb\"))\n",
    "all_train_tokens = pkl.load(open(\"data/all_train_tokens.p\", \"rb\"))\n",
    "\n",
    "val_data_tokens = pkl.load(open(\"data/val_data_tokens.p\", \"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "token2id, id2token = build_vocab(all_train_tokens, max_vocab_size=5000)\n",
    "train_data_indices = token2index_dataset(train_data_tokens)\n",
    "val_data_indices = token2index_dataset(val_data_tokens)\n",
    "#test_data_indices = token2index_dataset(test_data_tokens)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "train_dataset = Data(train_data_indices, train_targets)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "val_dataset = Data(val_data_indices, val_targets)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=collate_func,\n",
    "                                           shuffle=True)\n",
    "# no need for test data right now\n",
    "# test_dataset = NewsGroupDataset(test_data_indices, test_targets)\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "#                                            batch_size=BATCH_SIZE,\n",
    "#                                            collate_fn=newsgroup_collate_func,\n",
    "#                                            shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5002"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id2token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vecs = open('data/syn.expand.200d.vec').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_embedding = {}\n",
    "for vec in word_vecs:\n",
    "    word, wordvec = vec.split()[0], vec.split()[1:]\n",
    "    word = word.split('_')[0]\n",
    "    assert len(wordvec)==200, \"embedding size is not right\"\n",
    "    raw_embedding[word] = wordvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(id2token), 200))\n",
    "for word, i in token2id.items():\n",
    "    embedding_vector = raw_embedding.get(word)\n",
    "    if embedding_vector:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    elif word=='<unk>':\n",
    "        embedding_matrix[i] = np.random.uniform(-0.25, 0.25, 200)\n",
    "    else:\n",
    "        embedding_matrix[i] = np.zeros(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5002, 200)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(loader, model, every=20, learning_rate=1e-3, num_epochs=10, predict_type='baseline'):\n",
    "    # Criterion and Optimizer\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    # Train the model\n",
    "    total_step = len(loader)\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (data, lengths, labels) in enumerate(loader):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = model(data, lengths)\n",
    "            loss = criterion(outputs, labels)\n",
    "            # Backward and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # validate every n iterations\n",
    "            if i > 0 and i % every == 0:\n",
    "                # validate\n",
    "                loss_val, cor = test_model(val_loader, model)\n",
    "                print('Epoch: [{}/{}], Step: [{}/{}], Training batch loss: {}, Validation loss: {}, Validation correlation: {}'.format(\n",
    "                           epoch+1, num_epochs, i+1, len(train_loader), loss.item(), loss_val, cor))\n",
    "    torch.save(model.state_dict(), '{}_14epoch.pth'.format(predict_type))\n",
    "    \n",
    "    \n",
    "def test_model(loader, model):\n",
    "    \"\"\"\n",
    "    Help function that tests the model's performance on a dataset\n",
    "    @param: loader - data loader for the dataset to test against\n",
    "    \"\"\"\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    for data, lengths, labels in loader:\n",
    "        data_batch, lengths_batch, label_batch = data, lengths, labels\n",
    "        outputs = model(data_batch, lengths_batch)\n",
    "        predictions.extend(outputs.view(-1).tolist())\n",
    "        targets.extend(label_batch.tolist())\n",
    "    loss = criterion(torch.tensor(predictions), torch.tensor(targets))\n",
    "    correlation = spearmanr(predictions, targets).correlation\n",
    "    return loss, correlation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN-baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, emb_size=200, num_filters=100, num_chunks=100, filter_sizes=(3, 4, 5), dropout=0.5, pretrained=False):\n",
    "        super(CNN, self).__init__()\n",
    "        if pretrained:\n",
    "            self.embedding = nn.Embedding.from_pretrained(torch.from_numpy(embedding_matrix), freeze=True)\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(len(id2token), emb_size, padding_idx = PAD_IDX)\n",
    "        self.convs = nn.ModuleList(\n",
    "            [nn.Conv2d(1, num_filters, (k, emb_size)) for k in filter_sizes])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(num_filters * len(filter_sizes), 1)\n",
    "        self.fc2 = nn.Linear(num_chunks, 1)\n",
    "        self.num_chunks = num_chunks\n",
    "\n",
    "    \n",
    "    def chunk_maxpool(self, x, dim, k):\n",
    "        # maxpool over chunks and shrink size to k\n",
    "        chunks = torch.chunk(x, chunks=k, dim=dim)\n",
    "        chunks = [torch.max(ts, dim=dim).values.unsqueeze(dim) for ts in chunks]\n",
    "        return torch.cat(chunks, dim=dim)\n",
    "\n",
    "\n",
    "    def conv_and_pool(self, x, conv):\n",
    "        x = F.relu(conv(x)).squeeze(3)\n",
    "        #x = F.max_pool1d(x, x.size(2)).squeeze(2)\n",
    "        x = self.chunk_maxpool(x, 2, self.num_chunks)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x, lengths):\n",
    "        embed = self.embedding(x)\n",
    "        out = embed.unsqueeze(1)\n",
    "        out = torch.cat([self.conv_and_pool(out, conv) for conv in self.convs], 1)\n",
    "        #print('size after concat: ', out.size())\n",
    "        out = self.dropout(out).permute(0,2,1)\n",
    "        out = self.fc(out).squeeze(2)\n",
    "        #print ('size after fc: ', out.size())\n",
    "        out = self.fc2(out).squeeze(1)\n",
    "        #print ('output size: ', out.size())\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().double().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100 chunks\n",
    "train_model(train_loader, model, every=200, learning_rate = 1e-3, num_epochs = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN-pretrained-conv-layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CnnStc(nn.Module):\n",
    "    def __init__(self, emb_size=200, num_filters=100, num_chunks=100, filter_sizes=(3, 4, 5), dropout=0.5, pretrained=False, conv_static=False):\n",
    "        super(CnnStc, self).__init__()\n",
    "        if pretrained:\n",
    "            self.embedding = nn.Embedding.from_pretrained(torch.from_numpy(embedding_matrix), freeze=False)\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(len(id2token), emb_size, padding_idx = PAD_IDX)\n",
    "        self.convs = nn.ModuleList(\n",
    "            [nn.Conv2d(1, num_filters, (k, emb_size)) for k in filter_sizes])\n",
    "        if conv_static:\n",
    "            conv.weight.requires_grad = False\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(num_filters * len(filter_sizes), 1)\n",
    "        self.fc2 = nn.Linear(num_chunks, 1)\n",
    "        self.num_chunks = num_chunks\n",
    "\n",
    "    \n",
    "    def chunk_maxpool(self, x, dim, k):\n",
    "        # maxpool over chunks and shrink size to k\n",
    "        chunks = torch.chunk(x, chunks=k, dim=dim)\n",
    "        chunks = [torch.max(ts, dim=dim).values.unsqueeze(dim) for ts in chunks]\n",
    "        return torch.cat(chunks, dim=dim)\n",
    "\n",
    "\n",
    "    def conv_and_pool(self, x, conv):\n",
    "        x = F.relu(conv(x)).squeeze(3)\n",
    "        #x = F.max_pool1d(x, x.size(2)).squeeze(2)\n",
    "        x = self.chunk_maxpool(x, 2, self.num_chunks)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x, lengths):\n",
    "        embed = self.embedding(x)\n",
    "        out = embed.unsqueeze(1)\n",
    "        out = torch.cat([self.conv_and_pool(out, conv) for conv in self.convs], 1)\n",
    "        #print('size after concat: ', out.size())\n",
    "        out = self.dropout(out).permute(0,2,1)\n",
    "        out = self.fc(out).squeeze(2)\n",
    "        #print ('size after fc: ', out.size())\n",
    "        out = self.fc2(out).squeeze(1)\n",
    "        #print ('output size: ', out.size())\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_dict = torch.load('data/conv_nonstatic_fc_0_5_dropout.pt', map_location=device)\n",
    "pretrained_model = CnnStc(pretrained=True).double().to(device)\n",
    "for i in range(len(pretrained_model.convs)):\n",
    "    with torch.no_grad():\n",
    "        pretrained_model.convs[i].weight.copy_(pretrained_model_dict['convs.{}.weight'.format(i)].permute(0,2,1).unsqueeze(1))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/13], Step: [201/752], Training batch loss: 0.10735624238781864, Validation loss: 0.2934154272079468, Validation correlation: 0.13832066368942675\n",
      "Epoch: [1/13], Step: [401/752], Training batch loss: 0.25415098939686687, Validation loss: 0.3476417660713196, Validation correlation: 0.16204965981223235\n",
      "Epoch: [1/13], Step: [601/752], Training batch loss: 0.2791187567648869, Validation loss: 0.18884383141994476, Validation correlation: 0.19462689508667178\n",
      "Epoch: [2/13], Step: [201/752], Training batch loss: 0.2934287824217342, Validation loss: 0.2484191507101059, Validation correlation: 0.3111630003911598\n",
      "Epoch: [2/13], Step: [401/752], Training batch loss: 0.4884333977138745, Validation loss: 0.17875026166439056, Validation correlation: 0.3291538867540596\n",
      "Epoch: [2/13], Step: [601/752], Training batch loss: 0.3071800188497012, Validation loss: 0.16299310326576233, Validation correlation: 0.38122499981952446\n",
      "Epoch: [3/13], Step: [201/752], Training batch loss: 0.3074204030305283, Validation loss: 0.2510695457458496, Validation correlation: 0.3411872153501164\n",
      "Epoch: [3/13], Step: [401/752], Training batch loss: 0.12628141731617387, Validation loss: 0.14976516366004944, Validation correlation: 0.4479260691768886\n",
      "Epoch: [3/13], Step: [601/752], Training batch loss: 0.14556779889265217, Validation loss: 0.2141343653202057, Validation correlation: 0.46019331205050584\n",
      "Epoch: [4/13], Step: [201/752], Training batch loss: 0.07855531861099678, Validation loss: 0.1528729349374771, Validation correlation: 0.4730958122110584\n",
      "Epoch: [4/13], Step: [401/752], Training batch loss: 0.15948829926424649, Validation loss: 0.16537071764469147, Validation correlation: 0.4811616091439574\n",
      "Epoch: [4/13], Step: [601/752], Training batch loss: 0.06545609333120835, Validation loss: 0.14628706872463226, Validation correlation: 0.48385598063136\n",
      "Epoch: [5/13], Step: [201/752], Training batch loss: 0.12829300552726272, Validation loss: 0.3051658272743225, Validation correlation: 0.48777801059944337\n",
      "Epoch: [5/13], Step: [401/752], Training batch loss: 0.036411438376932226, Validation loss: 0.16725142300128937, Validation correlation: 0.4789332981996075\n",
      "Epoch: [5/13], Step: [601/752], Training batch loss: 0.09555153783995515, Validation loss: 0.17880818247795105, Validation correlation: 0.474259564832811\n",
      "Epoch: [6/13], Step: [201/752], Training batch loss: 0.19130385249798743, Validation loss: 0.14872518181800842, Validation correlation: 0.5192521270437083\n",
      "Epoch: [6/13], Step: [401/752], Training batch loss: 0.13446032404934047, Validation loss: 0.14879976212978363, Validation correlation: 0.5072460838410826\n",
      "Epoch: [6/13], Step: [601/752], Training batch loss: 0.02921265232276953, Validation loss: 0.1429232656955719, Validation correlation: 0.5239389396882969\n",
      "Epoch: [7/13], Step: [201/752], Training batch loss: 0.051864924055414444, Validation loss: 0.1456342488527298, Validation correlation: 0.5218719570767578\n",
      "Epoch: [7/13], Step: [401/752], Training batch loss: 0.023075608463598726, Validation loss: 0.1465132236480713, Validation correlation: 0.5373250573595492\n",
      "Epoch: [7/13], Step: [601/752], Training batch loss: 0.07579324957568066, Validation loss: 0.17934036254882812, Validation correlation: 0.4799387003525511\n",
      "Epoch: [8/13], Step: [201/752], Training batch loss: 0.06463547576969812, Validation loss: 0.17942658066749573, Validation correlation: 0.5464615015393112\n",
      "Epoch: [8/13], Step: [401/752], Training batch loss: 0.11701369997863423, Validation loss: 0.26858291029930115, Validation correlation: 0.5073989421441828\n",
      "Epoch: [8/13], Step: [601/752], Training batch loss: 0.09916066840682589, Validation loss: 0.147536501288414, Validation correlation: 0.5351581971632258\n",
      "Epoch: [9/13], Step: [201/752], Training batch loss: 0.048390940232167355, Validation loss: 0.1638912856578827, Validation correlation: 0.550733225170852\n",
      "Epoch: [9/13], Step: [401/752], Training batch loss: 0.14481542020407667, Validation loss: 0.17566776275634766, Validation correlation: 0.4352070640528572\n",
      "Epoch: [9/13], Step: [601/752], Training batch loss: 0.18339409247322647, Validation loss: 0.1490153819322586, Validation correlation: 0.546087288262055\n",
      "Epoch: [10/13], Step: [201/752], Training batch loss: 0.04398754403498756, Validation loss: 0.17129242420196533, Validation correlation: 0.5186406249923717\n",
      "Epoch: [10/13], Step: [401/752], Training batch loss: 0.060877988480659194, Validation loss: 0.1524667888879776, Validation correlation: 0.5585559874010345\n",
      "Epoch: [10/13], Step: [601/752], Training batch loss: 0.07471270420475937, Validation loss: 0.13311567902565002, Validation correlation: 0.5663620654752051\n",
      "Epoch: [11/13], Step: [201/752], Training batch loss: 0.11328765009535569, Validation loss: 0.14270205795764923, Validation correlation: 0.5389093646235066\n",
      "Epoch: [11/13], Step: [401/752], Training batch loss: 0.04072631618909176, Validation loss: 0.16135355830192566, Validation correlation: 0.47812960528209886\n",
      "Epoch: [11/13], Step: [601/752], Training batch loss: 0.06895000648675907, Validation loss: 0.1389993280172348, Validation correlation: 0.5562492240255172\n",
      "Epoch: [12/13], Step: [201/752], Training batch loss: 0.4267323849748547, Validation loss: 0.17151731252670288, Validation correlation: 0.5472302036410952\n",
      "Epoch: [12/13], Step: [401/752], Training batch loss: 0.11492084164978682, Validation loss: 0.13829250633716583, Validation correlation: 0.5463804691466899\n",
      "Epoch: [12/13], Step: [601/752], Training batch loss: 0.0703578089329413, Validation loss: 0.14461897313594818, Validation correlation: 0.533617002515723\n",
      "Epoch: [13/13], Step: [201/752], Training batch loss: 0.0571723636431114, Validation loss: 0.15070845186710358, Validation correlation: 0.5725715163349555\n",
      "Epoch: [13/13], Step: [401/752], Training batch loss: 0.18803644161242244, Validation loss: 0.15170954167842865, Validation correlation: 0.5730724658436112\n",
      "Epoch: [13/13], Step: [601/752], Training batch loss: 0.26583945992810687, Validation loss: 0.13711585104465485, Validation correlation: 0.5596142928755492\n"
     ]
    }
   ],
   "source": [
    "train_model(train_loader, pretrained_model, every=200, learning_rate = 1e-3, num_epochs = 13, predict_type='NTC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1695), 0.5501968749609781)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model = CnnStc(pretrained=True).double().to(device)\n",
    "pretrained_model.load_state_dict(torch.load('NTC_14epoch.pth'))\n",
    "pretrained_model.eval()\n",
    "test_model(val_loader, pretrained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stc_model_dict = torch.load('data/conv_nonstatic_fc_0_5_dropout.pt', map_location=device)\n",
    "stc_model = CnnStc(pretrained=True, conv_static=True).double().to(device)\n",
    "for i in range(len(stc_model.convs)):\n",
    "    with torch.no_grad():\n",
    "        stc_model.convs[i].weight.copy_(stc_model_dict['convs.{}.weight'.format(i)].permute(0,2,1).unsqueeze(1))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(train_loader, stc_model, every=200, learning_rate = 1e-3, num_epochs = 13, predict_type='STC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN-multichannel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CnnMulti(nn.Module):\n",
    "    def __init__(self, emb_size=200, num_filters=100, num_chunks=100, filter_sizes=(3, 4, 5), dropout=0.5, pretrained=False, conv_static=False, multichannel=False):\n",
    "        super(CnnMulti, self).__init__()\n",
    "        if pretrained:\n",
    "            self.embedding = nn.Embedding.from_pretrained(torch.from_numpy(embedding_matrix), freeze=False)\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(len(id2token), emb_size, padding_idx = PAD_IDX)\n",
    "            \n",
    "        self.multichannel = multichannel\n",
    "        if multichannel:\n",
    "            self.embedding_multi = nn.Embedding.from_pretrained(torch.from_numpy(embedding_matrix), freeze=True)\n",
    "            self.convs = nn.ModuleList(\n",
    "                [nn.Conv2d(1, num_filters*2, (k, emb_size*2)) for k in filter_sizes])\n",
    "        else:\n",
    "            self.convs = nn.ModuleList(\n",
    "                [nn.Conv2d(1, num_filters, (k, emb_size)) for k in filter_sizes])\n",
    "            \n",
    "        if conv_static:\n",
    "            for conv in self.convs:\n",
    "                conv.weight.requires_grad = False\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        if multichannel:\n",
    "            self.fc = nn.Linear(num_filters*2*len(filter_sizes), 1)\n",
    "        else:\n",
    "            self.fc = nn.Linear(num_filters*len(filter_sizes), 1)\n",
    " \n",
    "        self.fc2 = nn.Linear(num_chunks, 1)\n",
    "        self.num_chunks = num_chunks\n",
    "        \n",
    "        \n",
    "    def chunk_maxpool(self, x, dim, k):\n",
    "        # maxpool over chunks and shrink size to k\n",
    "        chunks = torch.chunk(x, chunks=k, dim=dim)\n",
    "        chunks = [torch.max(ts, dim=dim).values.unsqueeze(dim) for ts in chunks]\n",
    "        return torch.cat(chunks, dim=dim)\n",
    "        \n",
    "        \n",
    "    def conv_and_pool(self, x, conv):\n",
    "        x = F.relu(conv(x)).squeeze(3)\n",
    "        #x = F.max_pool1d(x, x.size(2)).squeeze(2)\n",
    "        # print('size after conv: ', x.size())\n",
    "        x = self.chunk_maxpool(x, 2, self.num_chunks)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x, lengths):\n",
    "        if self.multichannel:\n",
    "            embed = torch.cat((self.embedding(x), self.embedding_multi(x)), dim=2)\n",
    "        else:\n",
    "            embed = self.embedding(x)\n",
    "        out = embed.unsqueeze(1)\n",
    "        # print('size after embed: ', out.size())\n",
    "        out = torch.cat([self.conv_and_pool(out, conv) for conv in self.convs], 1)\n",
    "        # print('size after concat: ', out.size())\n",
    "        out = self.dropout(out).permute(0,2,1)\n",
    "        out = self.fc(out).squeeze(2)\n",
    "        #print ('size after fc: ', out.size())\n",
    "        out = self.fc2(out).squeeze(1)\n",
    "        #print ('output size: ', out.size())\n",
    "        return out\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mul_ntc_dict = torch.load('data/conv_nonstatic_fc_0_5_dropout.pt', map_location=device)\n",
    "mul_ntc_model = CnnMulti(pretrained=True, conv_static=False, multichannel=True).double().to(device)\n",
    "\n",
    "for i in range(len(mul_ntc_model.convs)):\n",
    "    with torch.no_grad():\n",
    "        new_weight = torch.zeros_like(mul_ntc_model.convs[i].weight, device=device, requires_grad=False)\n",
    "        new_weight[:100, :, :, :200].copy_(mul_ntc_dict['convs.{}.weight'.format(i)].permute(0,2,1).unsqueeze(1))\n",
    "        new_weight[100:,:,:, 200:].copy_(mul_ntc_dict['convs.{}.weight'.format(i)].permute(0,2,1).unsqueeze(1))\n",
    "        mul_ntc_model.convs[i].weight.copy_(new_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(train_loader, mul_ntc_model, every=200, learning_rate = 1e-3, num_epochs = 15, predict_type='mul-NTC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mul_stc_dict = torch.load('data/conv_nonstatic_fc_0_5_dropout.pt', map_location=device)\n",
    "mul_stc_model = CnnMulti(pretrained=True, conv_static=True, multichannel=True).double().to(device)\n",
    "\n",
    "for i in range(len(mul_stc_model.convs)):\n",
    "    with torch.no_grad():\n",
    "        new_weight = torch.zeros_like(mul_stc_model.convs[i].weight, device=device, requires_grad=False)\n",
    "        new_weight[:100, :, :, :200].copy_(mul_stc_dict['convs.{}.weight'.format(i)].permute(0,2,1).unsqueeze(1))\n",
    "        new_weight[100:,:,:, 200:].copy_(mul_stc_dict['convs.{}.weight'.format(i)].permute(0,2,1).unsqueeze(1))\n",
    "        mul_stc_model.convs[i].weight.copy_(new_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/14], Step: [201/752], Training batch loss: 0.3733088737266363, Validation loss: 0.2857387065887451, Validation correlation: 0.19462321891990322\n",
      "Epoch: [1/14], Step: [401/752], Training batch loss: 0.2705385034121349, Validation loss: 0.2615768611431122, Validation correlation: 0.26436904207717005\n",
      "Epoch: [1/14], Step: [601/752], Training batch loss: 0.5526325370363329, Validation loss: 0.18978549540042877, Validation correlation: 0.3127660344128434\n",
      "Epoch: [2/14], Step: [201/752], Training batch loss: 0.1866009646904164, Validation loss: 0.17762236297130585, Validation correlation: 0.326104090820013\n",
      "Epoch: [2/14], Step: [401/752], Training batch loss: 0.30348370400488667, Validation loss: 0.24659709632396698, Validation correlation: 0.3855784459445231\n",
      "Epoch: [2/14], Step: [601/752], Training batch loss: 0.10525024429989582, Validation loss: 0.24576710164546967, Validation correlation: 0.36400320961895144\n",
      "Epoch: [3/14], Step: [201/752], Training batch loss: 0.2667186560227735, Validation loss: 0.22652287781238556, Validation correlation: 0.37944506432003033\n",
      "Epoch: [3/14], Step: [401/752], Training batch loss: 0.1097010162753217, Validation loss: 0.19390685856342316, Validation correlation: 0.36332377354480894\n",
      "Epoch: [3/14], Step: [601/752], Training batch loss: 0.21322904444591756, Validation loss: 0.31863436102867126, Validation correlation: 0.4169344017480612\n",
      "Epoch: [4/14], Step: [201/752], Training batch loss: 0.2346305023518544, Validation loss: 0.44984474778175354, Validation correlation: 0.36782955041274895\n",
      "Epoch: [4/14], Step: [401/752], Training batch loss: 0.17134817306337957, Validation loss: 0.2932001054286957, Validation correlation: 0.4141137585028773\n",
      "Epoch: [4/14], Step: [601/752], Training batch loss: 0.23861997497959625, Validation loss: 0.27546730637550354, Validation correlation: 0.4298943430610213\n",
      "Epoch: [5/14], Step: [201/752], Training batch loss: 0.10255040225426452, Validation loss: 0.17521584033966064, Validation correlation: 0.39889088041896664\n",
      "Epoch: [5/14], Step: [401/752], Training batch loss: 0.17875199203610187, Validation loss: 0.24810637533664703, Validation correlation: 0.451735683602098\n",
      "Epoch: [5/14], Step: [601/752], Training batch loss: 0.13911244332144396, Validation loss: 0.20538903772830963, Validation correlation: 0.43007079640754403\n",
      "Epoch: [6/14], Step: [201/752], Training batch loss: 0.14848448100525638, Validation loss: 0.2301734983921051, Validation correlation: 0.41328874046911096\n",
      "Epoch: [6/14], Step: [401/752], Training batch loss: 0.22852338250985973, Validation loss: 0.24753490090370178, Validation correlation: 0.4153274001294691\n",
      "Epoch: [6/14], Step: [601/752], Training batch loss: 0.07151889253096791, Validation loss: 0.16987209022045135, Validation correlation: 0.4473363973117658\n",
      "Epoch: [7/14], Step: [201/752], Training batch loss: 0.09616417591945936, Validation loss: 0.21299204230308533, Validation correlation: 0.4162563326825978\n",
      "Epoch: [7/14], Step: [401/752], Training batch loss: 0.13116064882116524, Validation loss: 0.1609688699245453, Validation correlation: 0.468119596188206\n",
      "Epoch: [7/14], Step: [601/752], Training batch loss: 0.31120902013017204, Validation loss: 0.24886630475521088, Validation correlation: 0.4518530110208826\n",
      "Epoch: [8/14], Step: [201/752], Training batch loss: 0.15630284711141265, Validation loss: 0.19080066680908203, Validation correlation: 0.4338980024927257\n",
      "Epoch: [8/14], Step: [401/752], Training batch loss: 0.29103786415399713, Validation loss: 0.17609289288520813, Validation correlation: 0.4789378918858876\n",
      "Epoch: [8/14], Step: [601/752], Training batch loss: 0.2074332034085184, Validation loss: 0.2933175265789032, Validation correlation: 0.48476641125443987\n",
      "Epoch: [9/14], Step: [201/752], Training batch loss: 0.07759958803869316, Validation loss: 0.17802093923091888, Validation correlation: 0.4943487336710078\n",
      "Epoch: [9/14], Step: [401/752], Training batch loss: 0.237645135034325, Validation loss: 0.18559078872203827, Validation correlation: 0.49941508451352684\n",
      "Epoch: [9/14], Step: [601/752], Training batch loss: 0.110955426824956, Validation loss: 0.1693500578403473, Validation correlation: 0.46558303606093965\n",
      "Epoch: [10/14], Step: [201/752], Training batch loss: 0.03649806654806885, Validation loss: 0.17235969007015228, Validation correlation: 0.4740105525160907\n",
      "Epoch: [10/14], Step: [401/752], Training batch loss: 0.13851346185936003, Validation loss: 0.16209013760089874, Validation correlation: 0.5124252730079879\n",
      "Epoch: [10/14], Step: [601/752], Training batch loss: 0.20360935052227616, Validation loss: 0.17183725535869598, Validation correlation: 0.5059663965129123\n",
      "Epoch: [11/14], Step: [201/752], Training batch loss: 0.0752978798319468, Validation loss: 0.17395301163196564, Validation correlation: 0.49021693332457555\n",
      "Epoch: [11/14], Step: [401/752], Training batch loss: 0.04814799214995548, Validation loss: 0.1638442426919937, Validation correlation: 0.4847876410815607\n",
      "Epoch: [11/14], Step: [601/752], Training batch loss: 0.046667185607275084, Validation loss: 0.20840923488140106, Validation correlation: 0.506471058721435\n",
      "Epoch: [12/14], Step: [201/752], Training batch loss: 0.10754723286335108, Validation loss: 0.1518712192773819, Validation correlation: 0.48841715251217366\n",
      "Epoch: [12/14], Step: [401/752], Training batch loss: 0.08123133851073573, Validation loss: 0.23350369930267334, Validation correlation: 0.4360088426919924\n",
      "Epoch: [12/14], Step: [601/752], Training batch loss: 0.029243729228728588, Validation loss: 0.23094405233860016, Validation correlation: 0.5194608221143983\n",
      "Epoch: [13/14], Step: [201/752], Training batch loss: 0.06830776081448812, Validation loss: 0.14769110083580017, Validation correlation: 0.5238151551405218\n",
      "Epoch: [13/14], Step: [401/752], Training batch loss: 0.05622123454892478, Validation loss: 0.17143046855926514, Validation correlation: 0.5149870107307728\n",
      "Epoch: [13/14], Step: [601/752], Training batch loss: 0.06329723475802768, Validation loss: 0.20134590566158295, Validation correlation: 0.5147379334957733\n",
      "Epoch: [14/14], Step: [201/752], Training batch loss: 0.03427130015380278, Validation loss: 0.16377440094947815, Validation correlation: 0.5216221928396999\n",
      "Epoch: [14/14], Step: [401/752], Training batch loss: 0.03333319545101962, Validation loss: 0.17578323185443878, Validation correlation: 0.4669977675144278\n",
      "Epoch: [14/14], Step: [601/752], Training batch loss: 0.13383579973389895, Validation loss: 0.20611123740673065, Validation correlation: 0.5014402910660919\n"
     ]
    }
   ],
   "source": [
    "train_model(train_loader, mul_stc_model, every=200, learning_rate = 1e-3, num_epochs = 14, predict_type='mul-STC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
